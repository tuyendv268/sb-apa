{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuyendv/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPARAM_FILE = \"hparams/train.yaml\"\n",
    "DATA_FOLDER = \"data/TIMIT\"\n",
    "argv = [\n",
    "        HPARAM_FILE,\n",
    "        \"--data_folder\", DATA_FOLDER,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_file, run_opts, overrides = sb.parse_arguments(argv)\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import dataio_prep, AlignBrain\n",
    "\n",
    "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_brain = AlignBrain(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "align_brain.label_encoder = label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/codes/sb-apa/aligner/speechbrain/dataio/encoder.py:721: UserWarning: TextEncoder.expect_len was never called: assuming category count of 61 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEJS0_SX70.WAV',\n",
       " 'sig': tensor([-1.5259e-04,  6.1035e-05,  6.1035e-05,  ..., -1.2207e-04,\n",
       "         -3.0518e-05, -9.1553e-05]),\n",
       " 'phn_encoded': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0]),\n",
       " 'phn_ends': tensor([ 2040.,  2760.,  3640.,  4280.,  5138.,  6767.,  8520.,  9274., 10440.,\n",
       "         12360., 13640., 14640.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dir = \"/data/codes/sb-apa/aligner/results/augment_noise_CRDNN/1986/save/CKPT+2024-02-04+11-48-32+00\"\n",
    "\n",
    "model_ckpt_path = f'{ckpt_dir}/model.ckpt'\n",
    "output_ckpt_path = f'{ckpt_dir}/output.ckpt'\n",
    "\n",
    "model_state_dict = torch.load(model_ckpt_path)\n",
    "out_state_dict = torch.load(output_ckpt_path)\n",
    "\n",
    "align_brain.modules.model.load_state_dict(model_state_dict)\n",
    "align_brain.modules.output.load_state_dict(out_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.dataio.dataloader import make_dataloader\n",
    "\n",
    "dataloader = make_dataloader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break\n",
    "\n",
    "phns, phn_lens = batch.phn_encoded\n",
    "wavs, wav_lens = batch.sig\n",
    "phn_ends, _ = batch.phn_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = align_brain.infer(wavs, wav_lens, phns, phn_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.17391304347825"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs.shape[1] / len(alignments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 6, 6, 7, 8, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 20, 20, 21, 22, 23, 24, 25, 25, 25, 25, 26, 27, 27, 27, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 30, 30, 31, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2040.,  2760.,  3640.,  4280.,  5138.,  6767.,  8520.,  9274., 10440.,\n",
       "         12360., 13640., 14640.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phn_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.3238])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_brain.modules.aligner.calc_accuracy(alignments, phn_ends, phns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2er",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
