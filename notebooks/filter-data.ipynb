{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import librosa\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 12\n",
    "data_root_dir = \"/home/tuyendv/E2E-R/data/raw\" \n",
    "\n",
    "text_label = \"text\"\n",
    "n_sample_per_question_id = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    12: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/12\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-12\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-12_01082022_18092023.csv\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = type2path[data_type]\n",
    "\n",
    "data_name = os.path.basename(path_dict[\"metadata_path\"]).split(\".\")[0]\n",
    "data_dir = os.path.join(data_root_dir, data_name)\n",
    "    \n",
    "in_jsonl_path = f'{data_dir}/metadata-raw.jsonl'\n",
    "out_jsonl_path = f'{data_dir}/metadata.jsonl'\n",
    "out_csv_path = f'{data_dir}/metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in content]\n",
    "    data = pd.DataFrame(lines)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_jsonl_data_row_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for index in tqdm(data.index):\n",
    "            sample = data.loc[index].to_dict()\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "\n",
    "    print(f'###saved jsonl data to: {path}')\n",
    "    \n",
    "    \n",
    "hparams = {\n",
    "    \"in_jsonl_path\": in_jsonl_path,\n",
    "    \"out_csv_path\": out_csv_path,\n",
    "    \"out_jsonl_path\": out_jsonl_path,\n",
    "    \"n_sample_per_question_id\": n_sample_per_question_id,\n",
    "    \"text_label\": text_label\n",
    "}\n",
    "\n",
    "metadata = load_jsonl_data(hparams[\"in_jsonl_path\"])\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_with_text(data, text_label=\"text\", n_sample_per_question_id=268):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    filtered_data = []\n",
    "    for name, group in data.groupby(text_label):\n",
    "        if group.shape[0] >= n_sample_per_question_id:\n",
    "            samples = group.sample(n_sample_per_question_id)\n",
    "            filtered_data.append(samples)\n",
    "        else:\n",
    "            filtered_data.append(group)\n",
    "    filtered_data = pd.concat(filtered_data)\n",
    "    print(f'### shape after filtering: {filtered_data.shape}')\n",
    "    return filtered_data\n",
    "\n",
    "filtered_metadata = filter_data_with_text(\n",
    "    data=metadata, text_label=hparams[\"text_label\"],\n",
    "    n_sample_per_question_id=hparams[\"n_sample_per_question_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_score_distribution(data, label, phn_score_label=\"phone_scores\", wrd_score_label=\"word_scores\", utt_score_label=\"utterance_score\"):\n",
    "    names = [phn_score_label, wrd_score_label, utt_score_label]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n",
    "\n",
    "    for index, name in enumerate(names):\n",
    "        if name == utt_score_label:\n",
    "            scores = data.apply(lambda row: row[name], axis=1)\n",
    "        else:\n",
    "            scores = data.apply(lambda row: row[name], axis=1).explode()\n",
    "\n",
    "        sns.histplot(data=scores, bins=100, ax=axes[index])\n",
    "        axes[index].set_xlabel(name)\n",
    "\n",
    "    lengths = data.apply(lambda row: row[phn_score_label], axis=1).apply(len)\n",
    "    sns.histplot(data=lengths, bins=100, ax=axes[-1])\n",
    "    axes[-1].set_xlabel(\"length\")\n",
    "    axes[-1].set_ylabel(\"\")\n",
    "\n",
    "    plt.title(label)\n",
    "    return fig\n",
    "\n",
    "fig = plot_score_distribution(\n",
    "    filtered_metadata, label=os.path.basename(out_jsonl_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = filtered_metadata.arpas.apply(len)\n",
    "filtered_metadata = filtered_metadata[length < 124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save data visualization\n",
    "fig.savefig(f'{data_dir}/data-visualize.png')\n",
    "\n",
    "##save data in kaldi format\n",
    "filtered_metadata[[\"id\", \"text\"]].to_csv(\n",
    "    hparams[\"out_csv_path\"], sep=\"|\", index=None, header=None)\n",
    "\n",
    "##save data in jsonl format\n",
    "save_jsonl_data_row_level(\n",
    "    data=filtered_metadata, path=hparams[\"out_jsonl_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
