{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import random\n",
    "import re\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    12: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/10\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-10\",\n",
    "        \"metadata_path\": \"/data/metadata/stt-en/raw/vad-filtered-info_question_type-10_01082022_18092023.csv\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type_ = 12\n",
    "\n",
    "data_dir = \"/data/codes/sb-apa/data/scoring\"\n",
    "out_raw_json_path = f'{data_dir}/train-data-type-10.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_content</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>fidelity_class</th>\n",
       "      <th>created_at</th>\n",
       "      <th>total_time</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5580000</td>\n",
       "      <td>0</td>\n",
       "      <td>52077.0</td>\n",
       "      <td>66902</td>\n",
       "      <td>10</td>\n",
       "      <td>statistics</td>\n",
       "      <td>https://storage.googleapis.com/materials-eleme...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>2023-09-18 21:17:11</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5580001</td>\n",
       "      <td>0</td>\n",
       "      <td>88226.0</td>\n",
       "      <td>26144</td>\n",
       "      <td>10</td>\n",
       "      <td>Seat</td>\n",
       "      <td>https://storage.googleapis.com/materials-eleme...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>2023-09-18 21:17:11</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  is_deleted  user_id  question_id  question_type question_content  \\\n",
       "0  5580000           0  52077.0        66902             10       statistics   \n",
       "1  5580001           0  88226.0        26144             10             Seat   \n",
       "\n",
       "                                                 url  score fidelity_class  \\\n",
       "0  https://storage.googleapis.com/materials-eleme...   90.0       RELEVANT   \n",
       "1  https://storage.googleapis.com/materials-eleme...   53.0       RELEVANT   \n",
       "\n",
       "            created_at  total_time  word_count  \n",
       "0  2023-09-18 21:17:11        2.63         1.0  \n",
       "1  2023-09-18 21:17:11        2.45         1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict = type2path[_type_]\n",
    "\n",
    "hparams = {\n",
    "    \"json_dir\": path_dict[\"json_dir\"],\n",
    "    \"audio_dir\": path_dict[\"audio_dir\"],\n",
    "    \"metadata_path\": path_dict[\"metadata_path\"],\n",
    "    \"out_jsonl_path\": out_raw_json_path\n",
    "}\n",
    "\n",
    "metadata = pd.read_csv(hparams[\"metadata_path\"])\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1066f305a7e4083bfc7da845c7d2323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=136984), Label(value='0 / 136984')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095866, 12)\n",
      "(1095866, 12)\n"
     ]
    }
   ],
   "source": [
    "def is_valid_audio(audio_id):\n",
    "    abs_path = os.path.join(hparams[\"audio_dir\"], f'{audio_id}.wav')\n",
    "    if not os.path.exists(abs_path):\n",
    "        return False\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(abs_path)\n",
    "        if sr != 16000:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "is_exist =  metadata.id.parallel_apply(is_valid_audio)\n",
    "print(metadata.shape)\n",
    "metadata = metadata[is_exist]\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### shape before filtering: (1095866, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### shape after filtering: (1055250, 12)\n"
     ]
    }
   ],
   "source": [
    "def filter_data(data):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    data = data[data.total_time > 1.0]\n",
    "    data = data[data.total_time < 6.0]\n",
    "    data = data[data.word_count < 16]\n",
    "    # data = data[0:20000]\n",
    "    print(f'### shape after filtering: {data.shape}')\n",
    "    return data\n",
    "\n",
    "metadata = filter_data(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b599772632c4f32962b370603c04968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=131907), Label(value='0 / 131907')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    [{'id': '5580000', 'raw_text': 'statistics', '...\n",
       "1    [{'id': '5580001', 'raw_text': 'Seat', 'text':...\n",
       "2                                                   []\n",
       "3    [{'id': '5580004', 'raw_text': 'School', 'text...\n",
       "5    [{'id': '5580008', 'raw_text': 'precision', 't...\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_text(text):\n",
    "    text = re.sub(r\"[\\,\\.\\!\\?\\:\\;]\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    text = text.upper()\n",
    "\n",
    "    return text\n",
    "\n",
    "def is_valid_phoneme(phoneme):\n",
    "    if phoneme[\"phoneme_error_arpabet\"] != \"normal\":\n",
    "        trans = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[-1]\n",
    "        labels = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[0]\n",
    "        if len(labels.split(\" \")) >= 2:\n",
    "            return False\n",
    "        \n",
    "        if len(trans.split(\" \")) >= 2:\n",
    "            return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "def is_valid_word(word):\n",
    "    if len(word[\"phonemes\"]) != len(word[\"trans_arpabet\"].split()):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "            \n",
    "def parse_json_file(json_path):\n",
    "    decision2color = {\n",
    "        \"correct\": 2,\n",
    "        \"warning\":1,\n",
    "        \"error\":0\n",
    "    }\n",
    "\n",
    "    try: \n",
    "        with open(json_path, \"r\") as f:\n",
    "            content = json.load(f)\n",
    "        id = os.path.basename(json_path).split(\".\")[0]\n",
    "\n",
    "        utterances = []\n",
    "        for raw_utterance in content[\"utterance\"]:\n",
    "            id = id\n",
    "            utt_raw_text = raw_utterance[\"sentence\"]\n",
    "            utt_score = raw_utterance[\"nativeness_score\"]\n",
    "\n",
    "            audio_path = os.path.join(hparams[\"audio_dir\"], f'{id}.wav')\n",
    "\n",
    "            start_time = None\n",
    "            end_time = None\n",
    "            utt_uid = None\n",
    "            intonation_score = 0\n",
    "            fluency_score = 0\n",
    "            \n",
    "            utt_text = []\n",
    "            utt_arpas = []\n",
    "            utt_trans = [] \n",
    "            utt_phone_scores = []\n",
    "            utt_decisions = []\n",
    "            utt_word_scores = []\n",
    "            utt_word_ids = []\n",
    "            utt_rel_pos = []\n",
    "            \n",
    "            ignore = False\n",
    "            for word_id, word in enumerate(raw_utterance[\"words\"]):\n",
    "                word[\"trans_arpabet\"] = word[\"trans_arpabet\"].replace(\"AH0\", \"AX\")\n",
    "                \n",
    "                wrd_score = word[\"nativeness_score\"]\n",
    "                wrd_text = norm_text(word[\"text\"])\n",
    "                wrd_arpa = word[\"trans_arpabet\"].split()\n",
    "\n",
    "                if is_valid_word(word) == False:\n",
    "                    ignore = True\n",
    "                    break\n",
    "\n",
    "                for index, phoneme in enumerate(word[\"phonemes\"]):\n",
    "                    if is_valid_phoneme(phoneme) == False:\n",
    "                        ignore = True\n",
    "                        break\n",
    "                    \n",
    "                    if index == 0:\n",
    "                        rel_pos = 1\n",
    "                    elif index == (len(word[\"phonemes\"]) - 1):\n",
    "                        rel_pos = 3\n",
    "                    else:\n",
    "                        rel_pos = 2\n",
    "\n",
    "                    arpa = phoneme[\"trans_arpabet\"]\n",
    "                    decision = decision2color[phoneme[\"decision\"]]\n",
    "                    score = phoneme[\"nativeness_score\"] if phoneme[\"nativeness_score\"] >= 0 else 0\n",
    "                    tran = phoneme[\"trans_arpabet\"]\n",
    "                    \n",
    "                    if tran == \"SCHWA\":\n",
    "                        tran = \"AX\"\n",
    "\n",
    "                    utt_phone_scores.append(score)\n",
    "                    utt_word_ids.append(word_id)\n",
    "                    utt_trans.append(tran)\n",
    "                    utt_decisions.append(decision)\n",
    "                    utt_rel_pos.append(rel_pos)\n",
    "\n",
    "                utt_text.append(wrd_text)                \n",
    "                utt_word_scores.append(wrd_score)\n",
    "                utt_arpas.extend(wrd_arpa)\n",
    "            \n",
    "\n",
    "            utterance = {\n",
    "                \"id\": id,\n",
    "                \"raw_text\": utt_raw_text,\n",
    "                \"text\": \" \".join(utt_text),\n",
    "                \"utt_id\": utt_uid,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"arpas\": utt_arpas,\n",
    "                \"trans\": utt_trans,\n",
    "                \"phone_scores\": utt_phone_scores,\n",
    "                \"word_scores\": utt_word_scores,\n",
    "                \"decisions\": utt_decisions,\n",
    "                \"word_ids\": utt_word_ids,\n",
    "                \"rel_pos\": utt_rel_pos,\n",
    "                \"utterance_score\": utt_score,\n",
    "                \"intonation_score\": intonation_score,\n",
    "                \"fluency_score\": fluency_score,\n",
    "                \"audio_path\": audio_path\n",
    "            }\n",
    "            \n",
    "            if ignore == False:\n",
    "                utterances.append(utterance)\n",
    "        \n",
    "        return utterances\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "extracted_data = metadata.id.parallel_apply(\n",
    "    lambda x: parse_json_file(os.path.join(hparams[\"json_dir\"], f'{x}.json')))\n",
    "extracted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889735it [00:04, 209991.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data to:  /data/codes/sb-apa/data/scoring/train-data-type-10.jsonl\n"
     ]
    }
   ],
   "source": [
    "def save_jsonl_data_col_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        samples = (sample for sample in data.to_dict().values())\n",
    "        for sample in tqdm(samples):\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "    print(f'saved data to: ', path)\n",
    "\n",
    "data = extracted_data.explode().dropna()\n",
    "save_jsonl_data_col_level(data=data, path=hparams[\"out_jsonl_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "import librosa\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in content]\n",
    "    data = pd.DataFrame(lines)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "      <th>utt_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>arpas</th>\n",
       "      <th>trans</th>\n",
       "      <th>phone_scores</th>\n",
       "      <th>word_scores</th>\n",
       "      <th>decisions</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>rel_pos</th>\n",
       "      <th>utterance_score</th>\n",
       "      <th>intonation_score</th>\n",
       "      <th>fluency_score</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5580000</td>\n",
       "      <td>statistics</td>\n",
       "      <td>STATISTICS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[S, T, AX, T, IH1, S, T, IH0, K, S]</td>\n",
       "      <td>[S, T, AX, T, IH, S, T, IH, K, S]</td>\n",
       "      <td>[100, 100, 14.000000000000002, 94, 98, 96, 98,...</td>\n",
       "      <td>[90]</td>\n",
       "      <td>[2, 2, 0, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 3]</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/audio/prep-submission-audio/apa-type-10/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    raw_text        text utt_id start_time end_time  \\\n",
       "0  5580000  statistics  STATISTICS   None       None     None   \n",
       "\n",
       "                                 arpas                              trans  \\\n",
       "0  [S, T, AX, T, IH1, S, T, IH0, K, S]  [S, T, AX, T, IH, S, T, IH, K, S]   \n",
       "\n",
       "                                        phone_scores word_scores  \\\n",
       "0  [100, 100, 14.000000000000002, 94, 98, 96, 98,...        [90]   \n",
       "\n",
       "                        decisions                        word_ids  \\\n",
       "0  [2, 2, 0, 2, 2, 2, 2, 2, 2, 2]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                          rel_pos  utterance_score  intonation_score  \\\n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 3]               90                 0   \n",
       "\n",
       "   fluency_score                                         audio_path  \n",
       "0              0  /data/audio/prep-submission-audio/apa-type-10/...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/data/codes/sb-apa/data/scoring/train-data-type-10.jsonl\"\n",
    "\n",
    "metadata = load_jsonl_data(path)\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### shape before filtering: (889735, 17)\n",
      "### shape after filtering: (166801, 17)\n"
     ]
    }
   ],
   "source": [
    "def filter_data_with_text(data, text_label=\"text\", n_sample_per_question_id=268):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    filtered_data = []\n",
    "    for name, group in data.groupby(text_label):\n",
    "        if group.shape[0] >= n_sample_per_question_id:\n",
    "            samples = group.sample(n_sample_per_question_id)\n",
    "            filtered_data.append(samples)\n",
    "        else:\n",
    "            filtered_data.append(group)\n",
    "    filtered_data = pd.concat(filtered_data)\n",
    "    print(f'### shape after filtering: {filtered_data.shape}')\n",
    "    return filtered_data\n",
    "\n",
    "metadata = filter_data_with_text(\n",
    "    data=metadata, text_label=\"text\",\n",
    "    n_sample_per_question_id=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_phone_pure(arpas):\n",
    "    phone_pures = []\n",
    "    for phone in arpas:\n",
    "        phone_pures.append(re.sub(\"\\d\", \"\", phone))\n",
    "\n",
    "    phone_pures = \" \".join(phone_pures)\n",
    "    return phone_pures.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d23b5d9eb74322a34c7c6d16fdb25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=20851), Label(value='0 / 20851')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_duration(path):\n",
    "    wav, sr = librosa.load(path, sr=16000)\n",
    "    \n",
    "    return wav.shape[0]/sr\n",
    "\n",
    "metadata[\"duration\"]= metadata.audio_path.parallel_apply(get_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"word_scores\"] = metadata.apply(lambda row: [row[\"word_scores\"][index] for index in row[\"word_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_metadata, val_metadata = train_test_split(metadata, test_size=0.1, random_state=42)\n",
    "test_metadata, val_metadata = train_test_split(val_metadata, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train duration: 83.9903020486111\n",
      "test duration: 4.672772170138889\n",
      "val duration: 4.68741939236111\n"
     ]
    }
   ],
   "source": [
    "print(f'train duration: {train_metadata.duration.sum()/3600}')\n",
    "print(f'test duration: {test_metadata.duration.sum()/3600}')\n",
    "print(f'val duration: {val_metadata.duration.sum()/3600}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metadata.shape[0] // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:00<00:00, 37037.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9382/9382 [00:00<00:00, 37657.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:00<00:00, 37531.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_df_to_dict(metadata, max_length=32):\n",
    "    data = {}\n",
    "    total_sample = metadata.shape[0] // 16\n",
    "    print(total_sample)\n",
    "    metadata = metadata.sample(total_sample * 16)\n",
    "    for index in tqdm(metadata.index):\n",
    "        utterance_id = metadata[\"id\"][index]\n",
    "        wav = metadata[\"audio_path\"][index]\n",
    "        utt_score = str(metadata[\"utterance_score\"][index] / 50)\n",
    "        \n",
    "        text = metadata[\"text\"][index].lower()\n",
    "        spk_id = \"\"\n",
    "        phn = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "        phn_canonical = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "\n",
    "        scores = [str(ele/50) for ele in metadata[\"phone_scores\"][index]]\n",
    "        wrd_score = [str(ele/50) for ele in metadata[\"word_scores\"][index]]\n",
    "        wrd_ids = [str(ele + 1) for ele in metadata[\"word_ids\"][index]]\n",
    "        rel_pos = [str(ele) for ele in metadata[\"rel_pos\"][index]]\n",
    "\n",
    "        if len(scores) > max_length:\n",
    "            continue\n",
    "        \n",
    "        duration = 0.0\n",
    "        phn_ali = \"\"\n",
    "        phn_ali_start = \"\"\n",
    "        phn_ali_duration = \"\"\n",
    "\n",
    "        if phn is None:\n",
    "            continue\n",
    "\n",
    "        scores = \" \".join(scores)\n",
    "        wrd_score = \" \".join(wrd_score)\n",
    "        wrd_ids= \" \".join(wrd_ids)\n",
    "        rel_pos = \" \".join(rel_pos)\n",
    "\n",
    "        sample = {\n",
    "            \"utterance_id\": utterance_id,\n",
    "            \"wav\": wav,\n",
    "            \"text\": text,\n",
    "            \"spk_id\": spk_id,\n",
    "            \"phn\": phn,\n",
    "            \"phn_canonical\": phn_canonical,\n",
    "            \"phn_score\": scores,\n",
    "            \"wrd_score\": wrd_score,\n",
    "            \"utt_score\": utt_score,\n",
    "            \"wrd_id\": wrd_ids,\n",
    "            \"rel_pos\": rel_pos,\n",
    "            \"duration\": duration,\n",
    "            \"phn_ali\": phn_ali,\n",
    "            \"phn_ali_start\": phn_ali_start,\n",
    "            \"phn_ali_duration\": phn_ali_duration\n",
    "        }\n",
    "        \n",
    "        if utterance_id in data:\n",
    "            continue\n",
    "        \n",
    "        data[utterance_id] = sample\n",
    "    \n",
    "    return data\n",
    "\n",
    "test_metadata = convert_df_to_dict(test_metadata, max_length=48)\n",
    "train_metadata = convert_df_to_dict(train_metadata, max_length=48)\n",
    "val_metadata = convert_df_to_dict(val_metadata, max_length=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/train.json\n",
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/test.json\n",
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/val.json\n"
     ]
    }
   ],
   "source": [
    "def save_jsonl_data_row_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_obj = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "\n",
    "        f.write(f'{json_obj}\\n')\n",
    "\n",
    "    print(f'###saved jsonl data to: {path}')\n",
    "\n",
    "save_jsonl_data_row_level(data=train_metadata, path=f'{data_dir}/train.json')\n",
    "save_jsonl_data_row_level(data=test_metadata, path=f'{data_dir}/test.json')\n",
    "save_jsonl_data_row_level(data=val_metadata, path=f'{data_dir}/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
