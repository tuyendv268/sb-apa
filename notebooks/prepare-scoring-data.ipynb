{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import random\n",
    "import re\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    12: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/12\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-12\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-12_01082022_18092023.csv\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type_ = 12\n",
    "\n",
    "data_dir = \"/data/codes/sb-apa/data/scoring\"\n",
    "out_raw_json_path = f'{data_dir}/scoring-data-type-12.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_content</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>fidelity_class</th>\n",
       "      <th>created_at</th>\n",
       "      <th>total_time</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5580006</td>\n",
       "      <td>0</td>\n",
       "      <td>68133.0</td>\n",
       "      <td>155345</td>\n",
       "      <td>12</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>https://storage.googleapis.com/materials-eleme...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>2023-09-18 21:17:13</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5580010</td>\n",
       "      <td>0</td>\n",
       "      <td>68133.0</td>\n",
       "      <td>155346</td>\n",
       "      <td>12</td>\n",
       "      <td>chef</td>\n",
       "      <td>https://storage.googleapis.com/materials-eleme...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>UNRELATED</td>\n",
       "      <td>2023-09-18 21:17:16</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  is_deleted  user_id  question_id  question_type question_content  \\\n",
       "0  5580006           0  68133.0       155345             12       restaurant   \n",
       "1  5580010           0  68133.0       155346             12             chef   \n",
       "\n",
       "                                                 url  score fidelity_class  \\\n",
       "0  https://storage.googleapis.com/materials-eleme...   81.0       RELEVANT   \n",
       "1  https://storage.googleapis.com/materials-eleme...   20.0      UNRELATED   \n",
       "\n",
       "            created_at  total_time  word_count  \n",
       "0  2023-09-18 21:17:13        1.77         1.0  \n",
       "1  2023-09-18 21:17:16        1.09         1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict = type2path[_type_]\n",
    "\n",
    "hparams = {\n",
    "    \"json_dir\": path_dict[\"json_dir\"],\n",
    "    \"audio_dir\": path_dict[\"audio_dir\"],\n",
    "    \"metadata_path\": path_dict[\"metadata_path\"],\n",
    "    \"out_jsonl_path\": out_raw_json_path\n",
    "}\n",
    "\n",
    "metadata = pd.read_csv(hparams[\"metadata_path\"])\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8634f04b4a47adb63d4ba9b636a13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=113821), Label(value='0 / 113821')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910564, 12)\n",
      "(909649, 12)\n"
     ]
    }
   ],
   "source": [
    "def is_valid_audio(audio_id):\n",
    "    abs_path = os.path.join(hparams[\"audio_dir\"], f'{audio_id}.wav')\n",
    "    if not os.path.exists(abs_path):\n",
    "        return False\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(abs_path)\n",
    "        if sr != 16000:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "is_exist =  metadata.id.parallel_apply(is_valid_audio)\n",
    "print(metadata.shape)\n",
    "metadata = metadata[is_exist]\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### shape before filtering: (909649, 12)\n",
      "### shape after filtering: (857446, 12)\n"
     ]
    }
   ],
   "source": [
    "def filter_data(data):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    data = data[data.total_time > 1.0]\n",
    "    data = data[data.total_time < 6.0]\n",
    "    data = data[data.word_count < 16]\n",
    "    # data = data[0:20000]\n",
    "    print(f'### shape after filtering: {data.shape}')\n",
    "    return data\n",
    "\n",
    "metadata = filter_data(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a959dad511e493ba200c8dee47206ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=107181), Label(value='0 / 107181')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    [{'id': '5580006', 'raw_text': 'restaurant', '...\n",
       "1    [{'id': '5580010', 'raw_text': 'chef', 'text':...\n",
       "2    [{'id': '5580011', 'raw_text': 'middle-aged', ...\n",
       "3    [{'id': '5580017', 'raw_text': 'waitress', 'te...\n",
       "4    [{'id': '5580020', 'raw_text': 'director', 'te...\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_text(text):\n",
    "    text = re.sub(r\"[\\,\\.\\!\\?\\:\\;]\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    text = text.upper()\n",
    "\n",
    "    return text\n",
    "\n",
    "def is_valid_phoneme(phoneme):\n",
    "    if phoneme[\"phoneme_error_arpabet\"] != \"normal\":\n",
    "        trans = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[-1]\n",
    "        labels = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[0]\n",
    "        if len(labels.split(\" \")) >= 2:\n",
    "            return False\n",
    "        \n",
    "        if len(trans.split(\" \")) >= 2:\n",
    "            return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "def is_valid_word(word):\n",
    "    if len(word[\"phonemes\"]) != len(word[\"trans_arpabet\"].split()):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "            \n",
    "def parse_json_file(json_path):\n",
    "    decision2color = {\n",
    "        \"correct\": 2,\n",
    "        \"warning\":1,\n",
    "        \"error\":0\n",
    "    }\n",
    "\n",
    "    try: \n",
    "        with open(json_path, \"r\") as f:\n",
    "            content = json.load(f)\n",
    "        id = os.path.basename(json_path).split(\".\")[0]\n",
    "\n",
    "        utterances = []\n",
    "        for raw_utterance in content[\"utterance\"]:\n",
    "            id = id\n",
    "            utt_raw_text = raw_utterance[\"sentence\"]\n",
    "            utt_score = raw_utterance[\"nativeness_score\"]\n",
    "\n",
    "            audio_path = os.path.join(hparams[\"audio_dir\"], f'{id}.wav')\n",
    "\n",
    "            start_time = None\n",
    "            end_time = None\n",
    "            utt_uid = None\n",
    "            intonation_score = 0\n",
    "            fluency_score = 0\n",
    "            \n",
    "            utt_text = []\n",
    "            utt_arpas = []\n",
    "            utt_trans = [] \n",
    "            utt_phone_scores = []\n",
    "            utt_decisions = []\n",
    "            utt_word_scores = []\n",
    "            utt_word_ids = []\n",
    "            utt_rel_pos = []\n",
    "            \n",
    "            ignore = False\n",
    "            for word_id, word in enumerate(raw_utterance[\"words\"]):\n",
    "                word[\"trans_arpabet\"] = word[\"trans_arpabet\"].replace(\"AH0\", \"AX\")\n",
    "                \n",
    "                wrd_score = word[\"nativeness_score\"]\n",
    "                wrd_text = norm_text(word[\"text\"])\n",
    "                wrd_arpa = word[\"trans_arpabet\"].split()\n",
    "\n",
    "                if is_valid_word(word) == False:\n",
    "                    ignore = True\n",
    "                    break\n",
    "\n",
    "                for index, phoneme in enumerate(word[\"phonemes\"]):\n",
    "                    if is_valid_phoneme(phoneme) == False:\n",
    "                        ignore = True\n",
    "                        break\n",
    "                    \n",
    "                    if index == 0:\n",
    "                        rel_pos = 1\n",
    "                    elif index == (len(word[\"phonemes\"]) - 1):\n",
    "                        rel_pos = 3\n",
    "                    else:\n",
    "                        rel_pos = 2\n",
    "\n",
    "                    arpa = phoneme[\"trans_arpabet\"]\n",
    "                    decision = decision2color[phoneme[\"decision\"]]\n",
    "                    score = phoneme[\"nativeness_score\"] if phoneme[\"nativeness_score\"] >= 0 else 0\n",
    "                    tran = phoneme[\"trans_arpabet\"]\n",
    "\n",
    "                    utt_phone_scores.append(score)\n",
    "                    utt_word_ids.append(word_id)\n",
    "                    utt_trans.append(tran)\n",
    "                    utt_decisions.append(decision)\n",
    "                    utt_rel_pos.append(rel_pos)\n",
    "\n",
    "                utt_text.append(wrd_text)                \n",
    "                utt_word_scores.append(wrd_score)\n",
    "                utt_arpas.extend(wrd_arpa)\n",
    "            \n",
    "\n",
    "            utterance = {\n",
    "                \"id\": id,\n",
    "                \"raw_text\": utt_raw_text,\n",
    "                \"text\": \" \".join(utt_text),\n",
    "                \"utt_id\": utt_uid,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"arpas\": utt_arpas,\n",
    "                \"trans\": utt_trans,\n",
    "                \"phone_scores\": utt_phone_scores,\n",
    "                \"word_scores\": utt_word_scores,\n",
    "                \"decisions\": utt_decisions,\n",
    "                \"word_ids\": utt_word_ids,\n",
    "                \"rel_pos\": utt_rel_pos,\n",
    "                \"utterance_score\": utt_score,\n",
    "                \"intonation_score\": intonation_score,\n",
    "                \"fluency_score\": fluency_score,\n",
    "                \"audio_path\": audio_path\n",
    "            }\n",
    "            \n",
    "            if ignore == False:\n",
    "                utterances.append(utterance)\n",
    "        \n",
    "        return utterances\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "extracted_data = metadata.id.parallel_apply(\n",
    "    lambda x: parse_json_file(os.path.join(hparams[\"json_dir\"], f'{x}.json')))\n",
    "extracted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "689798it [00:03, 206178.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data to:  /data/codes/sb-apa/data/scoring/scoring-data-type-12.jsonl\n"
     ]
    }
   ],
   "source": [
    "def save_jsonl_data_col_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        samples = (sample for sample in data.to_dict().values())\n",
    "        for sample in tqdm(samples):\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "    print(f'saved data to: ', path)\n",
    "\n",
    "data = extracted_data.explode().dropna()\n",
    "save_jsonl_data_col_level(data=data, path=hparams[\"out_jsonl_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "import librosa\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in content]\n",
    "    data = pd.DataFrame(lines)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "      <th>utt_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>arpas</th>\n",
       "      <th>trans</th>\n",
       "      <th>phone_scores</th>\n",
       "      <th>word_scores</th>\n",
       "      <th>decisions</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>rel_pos</th>\n",
       "      <th>utterance_score</th>\n",
       "      <th>intonation_score</th>\n",
       "      <th>fluency_score</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5580006</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[R, EH1, S, T, R, AA0, N, T]</td>\n",
       "      <td>[R, EH, S, T, R, AA, N, T]</td>\n",
       "      <td>[100, 97, 98, 99, 94, 30, 98, 28.999999999999996]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 2, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 3]</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/audio/prep-submission-audio/apa-type-12/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    raw_text        text utt_id start_time end_time  \\\n",
       "0  5580006  restaurant  RESTAURANT   None       None     None   \n",
       "\n",
       "                          arpas                       trans  \\\n",
       "0  [R, EH1, S, T, R, AA0, N, T]  [R, EH, S, T, R, AA, N, T]   \n",
       "\n",
       "                                        phone_scores word_scores  \\\n",
       "0  [100, 97, 98, 99, 94, 30, 98, 28.999999999999996]        [81]   \n",
       "\n",
       "                  decisions                  word_ids  \\\n",
       "0  [2, 2, 2, 2, 2, 0, 2, 0]  [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                    rel_pos  utterance_score  intonation_score  fluency_score  \\\n",
       "0  [1, 2, 2, 2, 2, 2, 2, 3]             81.0                 0              0   \n",
       "\n",
       "                                          audio_path  \n",
       "0  /data/audio/prep-submission-audio/apa-type-12/...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/data/codes/sb-apa/data/scoring/scoring-data-type-12.jsonl\"\n",
    "\n",
    "metadata = load_jsonl_data(path)\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_phone_pure(arpas):\n",
    "    phone_pures = []\n",
    "    for phone in arpas:\n",
    "        phone_pures.append(re.sub(\"\\d\", \"\", phone))\n",
    "\n",
    "    phone_pures = \" \".join(phone_pures)\n",
    "    return phone_pures.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b3e165a6ba4122a2c24b3bb9780e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=86225), Label(value='0 / 86225')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_duration(path):\n",
    "    wav, sr = librosa.load(path, sr=16000)\n",
    "    \n",
    "    return wav.shape[0]/sr\n",
    "\n",
    "metadata[\"duration\"]= metadata.audio_path.parallel_apply(get_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"word_scores\"] = metadata.apply(lambda row: [row[\"word_scores\"][index] for index in row[\"word_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_metadata, val_metadata = train_test_split(metadata, test_size=0.1, random_state=42)\n",
    "test_metadata, val_metadata = train_test_split(val_metadata, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train duration: 404.25002256944447\n",
      "test duration: 22.42495027777778\n",
      "val duration: 22.510086006944448\n"
     ]
    }
   ],
   "source": [
    "print(f'train duration: {train_metadata.duration.sum()/3600}')\n",
    "print(f'test duration: {test_metadata.duration.sum()/3600}')\n",
    "print(f'val duration: {val_metadata.duration.sum()/3600}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34490/34490 [00:00<00:00, 36869.97it/s]\n",
      "100%|██████████| 620818/620818 [00:17<00:00, 36501.65it/s]\n",
      "100%|██████████| 34490/34490 [00:00<00:00, 36143.71it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_df_to_dict(metadata, max_length=48):\n",
    "    data = {}\n",
    "    for index in tqdm(metadata.index):\n",
    "        utterance_id = metadata[\"id\"][index]\n",
    "        wav = metadata[\"audio_path\"][index]\n",
    "        utt_score = str(metadata[\"utterance_score\"][index] / 50)\n",
    "        \n",
    "        text = metadata[\"text\"][index].lower()\n",
    "        spk_id = \"\"\n",
    "        phn = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "        phn_canonical = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "\n",
    "        scores = [str(ele/50) for ele in metadata[\"phone_scores\"][index]]\n",
    "        wrd_score = [str(ele/50) for ele in metadata[\"word_scores\"][index]]\n",
    "        wrd_ids = [str(ele + 1) for ele in metadata[\"word_ids\"][index]]\n",
    "        rel_pos = [str(ele) for ele in metadata[\"rel_pos\"][index]]\n",
    "\n",
    "        if len(scores) > max_length:\n",
    "            continue\n",
    "        \n",
    "        duration = 0.0\n",
    "        phn_ali = \"\"\n",
    "        phn_ali_start = \"\"\n",
    "        phn_ali_duration = \"\"\n",
    "\n",
    "        if phn is None:\n",
    "            continue\n",
    "\n",
    "        scores = \" \".join(scores)\n",
    "        wrd_score = \" \".join(wrd_score)\n",
    "        wrd_ids= \" \".join(wrd_ids)\n",
    "        rel_pos = \" \".join(rel_pos)\n",
    "\n",
    "        sample = {\n",
    "            \"utterance_id\": utterance_id,\n",
    "            \"wav\": wav,\n",
    "            \"text\": text,\n",
    "            \"spk_id\": spk_id,\n",
    "            \"phn\": phn,\n",
    "            \"phn_canonical\": phn_canonical,\n",
    "            \"phn_score\": scores,\n",
    "            \"wrd_score\": wrd_score,\n",
    "            \"utt_score\": utt_score,\n",
    "            \"wrd_id\": wrd_ids,\n",
    "            \"rel_pos\": rel_pos,\n",
    "            \"duration\": duration,\n",
    "            \"phn_ali\": phn_ali,\n",
    "            \"phn_ali_start\": phn_ali_start,\n",
    "            \"phn_ali_duration\": phn_ali_duration\n",
    "        }\n",
    "        \n",
    "        if utterance_id in data:\n",
    "            continue\n",
    "        \n",
    "        data[utterance_id] = sample\n",
    "    \n",
    "    return data\n",
    "\n",
    "test_metadata = convert_df_to_dict(test_metadata, max_length=48)\n",
    "train_metadata = convert_df_to_dict(train_metadata, max_length=48)\n",
    "val_metadata = convert_df_to_dict(val_metadata, max_length=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/train.json\n",
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/test.json\n",
      "###saved jsonl data to: /data/codes/sb-apa/data/scoring/val.json\n"
     ]
    }
   ],
   "source": [
    "def save_jsonl_data_row_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_obj = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "\n",
    "        f.write(f'{json_obj}\\n')\n",
    "\n",
    "    print(f'###saved jsonl data to: {path}')\n",
    "\n",
    "save_jsonl_data_row_level(data=train_metadata, path=f'{data_dir}/train.json')\n",
    "save_jsonl_data_row_level(data=test_metadata, path=f'{data_dir}/test.json')\n",
    "save_jsonl_data_row_level(data=val_metadata, path=f'{data_dir}/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
