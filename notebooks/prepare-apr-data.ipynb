{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import random\n",
    "import re\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    12: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/12\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-12\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/train/train-type-12.csv\"\n",
    "    },\n",
    "\n",
    "    10: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/10\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-10\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-10_01082022_18092023.csv\"\n",
    "    },\n",
    "    \n",
    "    9: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/9\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-9\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-9_19092023_21122023.csv\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = 12\n",
    "path_dict = type2path[_type]\n",
    "\n",
    "data_root_dir = \"/data/codes/E2E-R/data/apr\" \n",
    "data_name = os.path.basename(path_dict[\"metadata_path\"]).split(\".\")[0]\n",
    "data_dir = os.path.join(data_root_dir, data_name)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "out_raw_json_path = f'{data_dir}/metadata-raw.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"json_dir\": path_dict[\"json_dir\"],\n",
    "    \"audio_dir\": path_dict[\"audio_dir\"],\n",
    "    \"metadata_path\": path_dict[\"metadata_path\"],\n",
    "    \"out_jsonl_path\": out_raw_json_path\n",
    "}\n",
    "\n",
    "metadata = pd.read_csv(hparams[\"metadata_path\"])\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    data = data[data.total_time > 1.0]\n",
    "    data = data[data.total_time < 10.0]\n",
    "    data = data[data.word_count < 16]\n",
    "    # data = data[0:20000]\n",
    "    print(f'### shape after filtering: {data.shape}')\n",
    "    return data\n",
    "\n",
    "metadata = filter_data(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_audio(audio_id):\n",
    "    abs_path = os.path.join(hparams[\"audio_dir\"], f'{audio_id}.wav')\n",
    "    if not os.path.exists(abs_path):\n",
    "        return False\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(abs_path)\n",
    "        if sr != 16000:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "is_exist =  metadata.id.parallel_apply(is_valid_audio)\n",
    "print(metadata.shape)\n",
    "metadata = metadata[is_exist]\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_text(text):\n",
    "    text = re.sub(r\"[\\,\\.\\!\\?\\:\\;]\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    text = text.upper()\n",
    "\n",
    "    return text\n",
    "\n",
    "def is_valid_phoneme(phoneme):\n",
    "    if phoneme[\"nativeness_score\"] < 85:\n",
    "        return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "def is_valid_word(word):\n",
    "\n",
    "    return True\n",
    "            \n",
    "def parse_json_file(json_path):\n",
    "    decision2color = {\n",
    "        \"correct\": 2,\n",
    "        \"warning\":1,\n",
    "        \"error\":0\n",
    "    }\n",
    "\n",
    "    try: \n",
    "        with open(json_path, \"r\") as f:\n",
    "            content = json.load(f)\n",
    "        id = os.path.basename(json_path).split(\".\")[0]\n",
    "\n",
    "        utterances = []\n",
    "        for raw_utterance in content[\"utterance\"]:\n",
    "            id = id\n",
    "            utt_raw_text = raw_utterance[\"sentence\"]\n",
    "            utt_score = raw_utterance[\"nativeness_score\"]\n",
    "\n",
    "            audio_path = os.path.join(hparams[\"audio_dir\"], f'{id}.wav')\n",
    "\n",
    "            start_time = None\n",
    "            end_time = None\n",
    "            utt_uid = None\n",
    "            intonation_score = 0\n",
    "            fluency_score = 0\n",
    "            \n",
    "            utt_text = []\n",
    "            utt_arpas = []\n",
    "            utt_trans = [] \n",
    "            utt_phone_scores = []\n",
    "            utt_decisions = []\n",
    "            utt_word_scores = []\n",
    "            utt_word_ids = []\n",
    "            utt_alignments = []\n",
    "            \n",
    "            ignore = False\n",
    "            for word_id, word in enumerate(raw_utterance[\"words\"]):\n",
    "                word[\"trans_arpabet\"] = word[\"trans_arpabet\"].replace(\"AH0\", \"AX\")\n",
    "                \n",
    "                wrd_score = word[\"nativeness_score\"]\n",
    "                wrd_text = norm_text(word[\"text\"])\n",
    "                wrd_arpa = word[\"trans_arpabet\"].split()\n",
    "\n",
    "                if is_valid_word(word) == False:\n",
    "                    ignore = True\n",
    "                    break\n",
    "\n",
    "                for phoneme in word[\"phonemes\"]:\n",
    "                    if is_valid_phoneme(phoneme) == False:\n",
    "                        ignore = True\n",
    "                        break\n",
    "\n",
    "                    arpa = phoneme[\"trans_arpabet\"]\n",
    "                    decision = decision2color[phoneme[\"decision\"]]\n",
    "                    score = phoneme[\"nativeness_score\"] if phoneme[\"nativeness_score\"] >= 0 else 0\n",
    "                    tran = phoneme[\"trans_arpabet\"]\n",
    "                    alignment = [\n",
    "                        phoneme[\"start_time\"],\n",
    "                        phoneme[\"end_time\"]\n",
    "                    ]\n",
    "\n",
    "                    utt_alignments.append(alignment)\n",
    "                    utt_phone_scores.append(score)\n",
    "                    utt_word_ids.append(word_id)\n",
    "                    utt_trans.append(tran)\n",
    "                    utt_decisions.append(decision)\n",
    "\n",
    "                utt_text.append(wrd_text)                \n",
    "                utt_word_scores.append(wrd_score)\n",
    "                utt_arpas.extend(wrd_arpa)\n",
    "            \n",
    "\n",
    "            utterance = {\n",
    "                \"id\": id,\n",
    "                \"raw_text\": utt_raw_text,\n",
    "                \"text\": \" \".join(utt_text),\n",
    "                \"utt_id\": utt_uid,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"arpas\": utt_arpas,\n",
    "                \"trans\": utt_trans,\n",
    "                \"alignments\": utt_alignments,\n",
    "                \"phone_scores\": utt_phone_scores,\n",
    "                \"word_scores\": utt_word_scores,\n",
    "                \"decisions\": utt_decisions,\n",
    "                \"word_ids\": utt_word_ids,\n",
    "                \"utterance_score\": utt_score,\n",
    "                \"intonation_score\": intonation_score,\n",
    "                \"fluency_score\": fluency_score,\n",
    "                \"audio_path\": audio_path\n",
    "            }\n",
    "            \n",
    "            if ignore == False:\n",
    "                utterances.append(utterance)\n",
    "        \n",
    "        return utterances\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "extracted_data = metadata.id.parallel_apply(\n",
    "    lambda x: parse_json_file(os.path.join(hparams[\"json_dir\"], f'{x}.json')))\n",
    "extracted_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl_data_col_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        samples = (sample for sample in data.to_dict().values())\n",
    "        for sample in tqdm(samples):\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "    print(f'saved data to: ', path)\n",
    "\n",
    "data = extracted_data.explode().dropna()\n",
    "save_jsonl_data_col_level(data=data, path=hparams[\"out_jsonl_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare apr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import librosa\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 12\n",
    "data_root_dir = \"/home/tuyendv/E2E-R/data/apr\" \n",
    "\n",
    "text_label = \"text\"\n",
    "n_sample_per_question_id = 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    12: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/12\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-12\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/train/train-type-12.csv\"\n",
    "    },\n",
    "\n",
    "    10: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/10\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-10\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-10_01082022_18092023.csv\"\n",
    "    },\n",
    "    \n",
    "    9: {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/9\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-9\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/merged-info/info_question_type-9_01082022_18092023.csv\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = type2path[data_type]\n",
    "\n",
    "data_name = os.path.basename(path_dict[\"metadata_path\"]).split(\".\")[0]\n",
    "data_dir = os.path.join(data_root_dir, data_name)\n",
    "    \n",
    "in_jsonl_path = f'{data_dir}/metadata-raw.jsonl'\n",
    "out_jsonl_path = f'{data_dir}/metadata.jsonl'\n",
    "out_csv_path = f'{data_dir}/metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in content]\n",
    "    data = pd.DataFrame(lines)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_jsonl_data_row_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for index in tqdm(data.index):\n",
    "            sample = data.loc[index].to_dict()\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "\n",
    "    print(f'###saved jsonl data to: {path}')\n",
    "    \n",
    "    \n",
    "hparams = {\n",
    "    \"in_jsonl_path\": in_jsonl_path,\n",
    "    \"out_csv_path\": out_csv_path,\n",
    "    \"out_jsonl_path\": out_jsonl_path,\n",
    "    \"n_sample_per_question_id\": n_sample_per_question_id,\n",
    "    \"text_label\": text_label\n",
    "}\n",
    "\n",
    "metadata = load_jsonl_data(hparams[\"in_jsonl_path\"])\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_with_text(data, text_label=\"text\", n_sample_per_question_id=268):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    filtered_data = []\n",
    "    for name, group in data.groupby(text_label):\n",
    "        if group.shape[0] >= n_sample_per_question_id:\n",
    "            samples = group.sample(n_sample_per_question_id)\n",
    "            filtered_data.append(samples)\n",
    "        else:\n",
    "            filtered_data.append(group)\n",
    "    filtered_data = pd.concat(filtered_data)\n",
    "    print(f'### shape after filtering: {filtered_data.shape}')\n",
    "    return filtered_data\n",
    "\n",
    "filtered_metadata = filter_data_with_text(\n",
    "    data=metadata, text_label=hparams[\"text_label\"],\n",
    "    n_sample_per_question_id=hparams[\"n_sample_per_question_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alignment(arpas, alignments):\n",
    "    parsed_alignments = []\n",
    "\n",
    "    previous = None\n",
    "    for arpa, current in zip(arpas, alignments):\n",
    "        if previous is None:\n",
    "            parsed_alignments.append(\n",
    "                [\n",
    "                    \"SIL\",\n",
    "                    0,\n",
    "                    current[0]\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            if previous[1] < current[0]: \n",
    "                parsed_alignments.append(\n",
    "                    [\n",
    "                        \"SIL\",\n",
    "                        previous[1],\n",
    "                        current[0]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if arpa == \"SCHWA\":\n",
    "            arpa = \"AH\"\n",
    "\n",
    "        parsed_alignments.append(\n",
    "            [   \n",
    "                arpa, \n",
    "                current[0],\n",
    "                current[1]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        previous = current\n",
    "\n",
    "    return parsed_alignments\n",
    "\n",
    "audio_dir = \"/home/tuyendv/E2E-R/data/apr/train-type-12/wav\"\n",
    "filtered_metadata[\"alignments\"] = filtered_metadata.apply(lambda row: parse_alignment(row[\"trans\"], row[\"alignments\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(filtered_metadata, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().drop(columns=[\"index\"])\n",
    "test = test.reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import librosa \n",
    "\n",
    "data = {}\n",
    "\n",
    "for index in tqdm(test.index):\n",
    "    row = filtered_metadata.iloc[index]\n",
    "\n",
    "    id = row[\"id\"]\n",
    "    wav = f'{audio_dir}/{id}.wav'\n",
    "    \n",
    "    waveform, sr = librosa.load(wav, sr=16000)\n",
    "    duration = waveform.shape[0] / sr\n",
    "    spk_id = None\n",
    "    wrd = row[\"text\"].lower()\n",
    "\n",
    "    phn = [phone[0] for phone in row[\"alignments\"]] + [\"SIL\", ]\n",
    "    phn = \" \".join(phn).lower()\n",
    "\n",
    "    ground_truth_phn_ends = \" \".join([str(int(phone[-1]*16000)) for phone in row[\"alignments\"]] + [str(waveform.shape[0])])\n",
    "\n",
    "    assert id not in data\n",
    "\n",
    "    data[id] = {\n",
    "        \"wav\" : wav,\n",
    "        \"duration\": duration,\n",
    "        \"spk_id\": spk_id,\n",
    "        \"phn\": phn,\n",
    "        \"wrd\": wrd,\n",
    "        \"ground_truth_phn_ends\": ground_truth_phn_ends\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/tuyendv/E2E-R/data/apr/train-type-12/val.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json_obj = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "    f.write(json_obj)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
