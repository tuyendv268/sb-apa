{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import random\n",
    "import re\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "\n",
    "apr_datadir = \"/data/codes/sb-apa/data/prep-apr\"\n",
    "apr_data = {}\n",
    "for file in glob(f'{apr_datadir}/*'):\n",
    "    json_obj = json.load(open(file))\n",
    "    apr_data.update(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type_ = \"train-type-9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2path = {\n",
    "    \"train-type-9\": {\n",
    "        \"json_dir\": \"/data/metadata/apa-en/marking-data/9\",\n",
    "        \"audio_dir\": \"/data/audio/prep-submission-audio/apa-type-9\",\n",
    "        \"metadata_path\": \"/data/metadata/apa-en/train/train-type-9.csv\",\n",
    "        \"out_dir\": \"/data/codes/sb-apa/data/scoring/apa-type-9/\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = type2path[_type_]\n",
    "\n",
    "hparams = {\n",
    "    \"json_dir\": path_dict[\"json_dir\"],\n",
    "    \"audio_dir\": path_dict[\"audio_dir\"],\n",
    "    \"metadata_path\": path_dict[\"metadata_path\"],\n",
    "    \"out_jsonl_path\": f'{path_dict[\"out_dir\"]}/{_type_}.jsonl'\n",
    "}\n",
    "\n",
    "metadata = pd.read_csv(hparams[\"metadata_path\"])\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_audio(audio_id):\n",
    "    abs_path = os.path.join(hparams[\"audio_dir\"], f'{audio_id}.wav')\n",
    "    if not os.path.exists(abs_path):\n",
    "        return False\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(abs_path)\n",
    "        if sr != 16000:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "is_exist =  metadata.id.parallel_apply(is_valid_audio)\n",
    "print(metadata.shape)\n",
    "metadata = metadata[is_exist]\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    data = data[data.total_time > 1.0]\n",
    "    # data = data[data.total_time < 6.0]\n",
    "    # data = data[data.word_count < 16]\n",
    "    # data = data[0:20000]\n",
    "    print(f'### shape after filtering: {data.shape}')\n",
    "    return data\n",
    "\n",
    "metadata = filter_data(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_text(text):\n",
    "    text = re.sub(r\"[\\,\\.\\!\\?\\:\\;]\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    text = text.upper()\n",
    "\n",
    "    return text\n",
    "\n",
    "def is_valid_phoneme(phoneme):\n",
    "    # if phoneme[\"phoneme_error_arpabet\"] != \"normal\":\n",
    "    #     trans = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[-1]\n",
    "    #     labels = phoneme[\"phoneme_error_arpabet\"].split(\" - \")[0]\n",
    "    #     if len(labels.split(\" \")) >= 2:\n",
    "    #         return False\n",
    "        \n",
    "    #     if len(trans.split(\" \")) >= 2:\n",
    "    #         return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "def is_valid_word(word):\n",
    "    if len(word[\"phonemes\"]) != len(word[\"trans_arpabet\"].split()):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "            \n",
    "def parse_json_file(json_path):\n",
    "    decision2color = {\n",
    "        \"correct\": 2,\n",
    "        \"warning\":1,\n",
    "        \"incorrect\":0\n",
    "    }\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        content = json.load(f)\n",
    "        \n",
    "    id = os.path.basename(json_path).split(\".\")[0]\n",
    "    audio_path = os.path.join(hparams[\"audio_dir\"], f'{id}.wav')\n",
    "\n",
    "    utterances = []\n",
    "    for raw_utterance in content[\"utterances\"]:\n",
    "        id = id\n",
    "        utt_raw_text = raw_utterance[\"text\"]\n",
    "        utt_uid = raw_utterance[\"utterance_id\"]\n",
    "        start_time = raw_utterance[\"start_time\"]\n",
    "        end_time = raw_utterance[\"end_time\"]\n",
    "        \n",
    "        if raw_utterance[\"result\"] is None or f'{id}{utt_uid}' not in apr_data:\n",
    "            continue\n",
    "        \n",
    "        raw_utterance = raw_utterance[\"result\"]\n",
    "        \n",
    "        utt_score = raw_utterance[\"nativeness_score\"]\n",
    "        intonation_score = raw_utterance[\"intonation_score\"]\n",
    "        fluency_score = raw_utterance[\"fluency_score\"]\n",
    "        \n",
    "        if intonation_score is None or fluency_score is None:\n",
    "            continue\n",
    "        \n",
    "        utt_text = []\n",
    "        utt_arpas = []\n",
    "        utt_trans = [] \n",
    "        utt_phone_scores = []\n",
    "        utt_decisions = []\n",
    "        utt_word_scores = []\n",
    "        utt_word_ids = []\n",
    "        utt_rel_pos = []\n",
    "        \n",
    "        ignore = False\n",
    "        for word_id, word in enumerate(raw_utterance[\"words\"]):\n",
    "            word[\"trans_arpabet\"] = word[\"trans_arpabet\"].replace(\"AH0\", \"AX\")\n",
    "            \n",
    "            wrd_score = word[\"nativeness_score\"]\n",
    "            wrd_text = norm_text(word[\"text\"])\n",
    "            wrd_arpa = word[\"trans_arpabet\"].split()\n",
    "\n",
    "            if is_valid_word(word) == False:\n",
    "                ignore = True\n",
    "                break\n",
    "\n",
    "            for index, phoneme in enumerate(word[\"phonemes\"]):\n",
    "                if is_valid_phoneme(phoneme) == False:\n",
    "                    ignore = True\n",
    "                    break\n",
    "                \n",
    "                if index == 0:\n",
    "                    rel_pos = 1\n",
    "                elif index == (len(word[\"phonemes\"]) - 1):\n",
    "                    rel_pos = 3\n",
    "                else:\n",
    "                    rel_pos = 2\n",
    "\n",
    "                arpa = phoneme[\"trans_arpabet\"]\n",
    "                decision = decision2color[phoneme[\"decision\"]]\n",
    "                score = phoneme[\"nativeness_score\"] if phoneme[\"nativeness_score\"] >= 0 else 0\n",
    "                tran = phoneme[\"trans_arpabet\"]\n",
    "                \n",
    "                if tran == \"SCHWA\":\n",
    "                    tran = \"AX\"\n",
    "\n",
    "                utt_phone_scores.append(score)\n",
    "                utt_word_ids.append(word_id)\n",
    "                utt_trans.append(tran)\n",
    "                utt_decisions.append(decision)\n",
    "                utt_rel_pos.append(rel_pos)\n",
    "\n",
    "            utt_text.append(wrd_text)                \n",
    "            utt_word_scores.append(wrd_score)\n",
    "            utt_arpas.extend(wrd_arpa)\n",
    "        \n",
    "\n",
    "        utterance = {\n",
    "            \"id\": id,\n",
    "            \"raw_text\": utt_raw_text,\n",
    "            \"text\": \" \".join(utt_text),\n",
    "            \"utt_id\": utt_uid,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"arpas\": utt_arpas,\n",
    "            \"trans\": utt_trans,\n",
    "            \"phone_scores\": utt_phone_scores,\n",
    "            \"word_scores\": utt_word_scores,\n",
    "            \"decisions\": utt_decisions,\n",
    "            \"word_ids\": utt_word_ids,\n",
    "            \"rel_pos\": utt_rel_pos,\n",
    "            \"utterance_score\": utt_score,\n",
    "            \"intonation_score\": intonation_score,\n",
    "            \"fluency_score\": fluency_score,\n",
    "            \"audio_path\": audio_path\n",
    "        }\n",
    "        \n",
    "        if ignore == False:\n",
    "            utterances.append(utterance)\n",
    "        \n",
    "        return utterances\n",
    "\n",
    "extracted_data = metadata.id.parallel_apply(\n",
    "    lambda x: parse_json_file(os.path.join(hparams[\"json_dir\"], f'{x}.json')))\n",
    "extracted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl_data_col_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        samples = (sample for sample in data.to_dict().values())\n",
    "        for sample in tqdm(samples):\n",
    "            json_obj = json.dumps(sample)\n",
    "\n",
    "            f.write(f'{json_obj}\\n')\n",
    "    print(f'saved data to: ', path)\n",
    "\n",
    "data = extracted_data.explode().dropna()\n",
    "save_jsonl_data_col_level(data=data, path=hparams[\"out_jsonl_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in content]\n",
    "    data = pd.DataFrame(lines)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/data/codes/sb-apa/data/scoring/train-data-type-10.jsonl\"\n",
    "wav_dir = \"/data/codes/sb-apa/kaldi/data/stt-data/wav\"\n",
    "path = hparams[\"out_jsonl_path\"]\n",
    "\n",
    "metadata = load_jsonl_data(path)\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"audio_path\"] = metadata.apply(lambda row: os.path.join(wav_dir, f'{row[\"id\"]}{row[\"utt_id\"]}.wav'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_with_text(data, text_label=\"text\", n_sample_per_question_id=268):\n",
    "    print(f'### shape before filtering: {data.shape}')\n",
    "    filtered_data = []\n",
    "    for name, group in data.groupby(text_label):\n",
    "        if group.shape[0] >= n_sample_per_question_id:\n",
    "            samples = group.sample(n_sample_per_question_id)\n",
    "            filtered_data.append(samples)\n",
    "        else:\n",
    "            filtered_data.append(group)\n",
    "    filtered_data = pd.concat(filtered_data)\n",
    "    print(f'### shape after filtering: {filtered_data.shape}')\n",
    "    return filtered_data\n",
    "\n",
    "metadata = filter_data_with_text(\n",
    "    data=metadata, text_label=\"text\",\n",
    "    n_sample_per_question_id=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_phone_pure(arpas):\n",
    "    phone_pures = []\n",
    "    for phone in arpas:\n",
    "        phone_pures.append(re.sub(\"\\d\", \"\", phone))\n",
    "\n",
    "    phone_pures = \" \".join(phone_pures)\n",
    "    return phone_pures.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(path):\n",
    "    wav, sr = librosa.load(path, sr=16000)\n",
    "    \n",
    "    return wav.shape[0]/sr\n",
    "\n",
    "metadata[\"duration\"]= metadata.audio_path.parallel_apply(get_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"word_scores\"] = metadata.apply(lambda row: [row[\"word_scores\"][index] for index in row[\"word_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_metadata, val_metadata = train_test_split(metadata, test_size=0.05, random_state=42)\n",
    "# test_metadata, val_metadata = train_test_split(val_metadata, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train duration: {train_metadata.duration.sum()/3600}')\n",
    "# print(f'test duration: {test_metadata.duration.sum()/3600}')\n",
    "print(f'val duration: {val_metadata.duration.sum()/3600}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_dict(metadata, max_length=32):\n",
    "    data = {}\n",
    "    total_sample = metadata.shape[0] // 16\n",
    "    print(total_sample)\n",
    "    metadata = metadata.sample(total_sample * 16)\n",
    "    for index in tqdm(metadata.index):\n",
    "        utterance_id = metadata[\"id\"][index]\n",
    "        wav = metadata[\"audio_path\"][index]\n",
    "        utt_score = str(metadata[\"utterance_score\"][index] / 50)\n",
    "        \n",
    "        text = metadata[\"text\"][index].lower()\n",
    "        spk_id = \"\"\n",
    "        phn = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "        phn_canonical = convert_to_phone_pure(metadata[\"arpas\"][index])\n",
    "\n",
    "        scores = [str(ele/50) for ele in metadata[\"phone_scores\"][index]]\n",
    "        wrd_score = [str(ele/50) for ele in metadata[\"word_scores\"][index]]\n",
    "        wrd_ids = [str(ele + 1) for ele in metadata[\"word_ids\"][index]]\n",
    "        rel_pos = [str(ele) for ele in metadata[\"rel_pos\"][index]]\n",
    "\n",
    "        if len(scores) > max_length:\n",
    "            continue\n",
    "        \n",
    "        duration = 0.0\n",
    "        phn_ali = \"\"\n",
    "        phn_ali_start = \"\"\n",
    "        phn_ali_duration = \"\"\n",
    "\n",
    "        if phn is None:\n",
    "            continue\n",
    "\n",
    "        scores = \" \".join(scores)\n",
    "        wrd_score = \" \".join(wrd_score)\n",
    "        wrd_ids= \" \".join(wrd_ids)\n",
    "        rel_pos = \" \".join(rel_pos)\n",
    "\n",
    "        sample = {\n",
    "            \"utterance_id\": utterance_id,\n",
    "            \"wav\": wav,\n",
    "            \"text\": text,\n",
    "            \"spk_id\": spk_id,\n",
    "            \"phn\": phn,\n",
    "            \"phn_canonical\": phn_canonical,\n",
    "            \"phn_score\": scores,\n",
    "            \"wrd_score\": wrd_score,\n",
    "            \"utt_score\": utt_score,\n",
    "            \"wrd_id\": wrd_ids,\n",
    "            \"rel_pos\": rel_pos,\n",
    "            \"duration\": duration,\n",
    "            \"phn_ali\": phn_ali,\n",
    "            \"phn_ali_start\": phn_ali_start,\n",
    "            \"phn_ali_duration\": phn_ali_duration\n",
    "        }\n",
    "        \n",
    "        if utterance_id in data:\n",
    "            continue\n",
    "        \n",
    "        data[utterance_id] = sample\n",
    "    \n",
    "    return data\n",
    "\n",
    "metadata = convert_df_to_dict(metadata, max_length=256)\n",
    "train_metadata = convert_df_to_dict(train_metadata, max_length=256)\n",
    "# test_metadata = convert_df_to_dict(test_metadata, max_length=256)\n",
    "val_metadata = convert_df_to_dict(val_metadata, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl_data_row_level(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_obj = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "\n",
    "        f.write(f'{json_obj}\\n')\n",
    "\n",
    "    print(f'###saved jsonl data to: {path}')\n",
    "\n",
    "save_jsonl_data_row_level(data=metadata, path=f'{path_dict[\"out_dir\"]}/train.json')\n",
    "# save_jsonl_data_row_level(data=test_metadata, path=f'{data_dir}/test.json')\n",
    "# save_jsonl_data_row_level(data=metadata, path=f'{data_dir}/test-type-12-short.json')\n",
    "save_jsonl_data_row_level(data=val_metadata, path=f'{path_dict[\"out_dir\"]}/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
