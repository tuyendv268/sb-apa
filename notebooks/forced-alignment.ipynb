{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/sb-apa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuyendv/miniconda3/envs/e2er/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/sb-apa/\n",
    "\n",
    "from src.brain import get_brain_class\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import speechbrain as sb\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from utils.arpa import arpa_to_ipa\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(hparams):\n",
    "    wav2vec2_ckpt_path = f'{ckpt_path}/wav2vec2.ckpt'\n",
    "    model_ckpt_path = f'{ckpt_path}/model.ckpt'\n",
    "\n",
    "    wav2vec2_state_dict = torch.load(wav2vec2_ckpt_path)\n",
    "    model_state_dict = torch.load(model_ckpt_path)\n",
    "\n",
    "    hparams[\"wav2vec2\"].load_state_dict(wav2vec2_state_dict)\n",
    "    hparams[\"model\"].load_state_dict(model_state_dict)\n",
    "\n",
    "    return hparams\n",
    "\n",
    "def init_model(hparams):\n",
    "    brain_class = get_brain_class(hparams)\n",
    "\n",
    "    model = brain_class(\n",
    "            modules=hparams[\"modules\"],\n",
    "            hparams=hparams,\n",
    "            run_opts=run_opts,\n",
    "            checkpointer=hparams[\"checkpointer\"],\n",
    "        )\n",
    "\n",
    "    hparams = load_state_dict(hparams)\n",
    "    \n",
    "    for key, value in hparams[\"modules\"].items():\n",
    "        value.eval()\n",
    "    \n",
    "    return model, hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "APR_DATA_FOLDER = f'{DATA_DIR}/apr/'\n",
    "\n",
    "RESULTS_FOLDER = f'{DATA_DIR}/results/'\n",
    "EXP_METADATA_FILE = f'{RESULTS_FOLDER}/exp_metadata.csv'\n",
    "APR_RESULTS_FILE = f'{RESULTS_FOLDER}/results_scoring.csv'\n",
    "EPOCH_RESULTS_DIR = f'{RESULTS_FOLDER}/epoch_results'\n",
    "PARAMS_DIR= f'{RESULTS_FOLDER}/params'\n",
    "\n",
    "\n",
    "MODEL_TYPE = \"w2v2\"\n",
    "SCORING_TYPE=\"\"\n",
    "\n",
    "APR_MODEL_DIR = f\"pretrained/apr\"\n",
    "PRETRAINED_MODEL_DIR = f\"pretrained/apr\"\n",
    "SCORING_HPARAM_FILE = f\"hparams/apr.yml\"\n",
    "\n",
    "argv = [\n",
    "    SCORING_HPARAM_FILE,\n",
    "    \"--data_folder\", APR_DATA_FOLDER,\n",
    "    \"--exp_folder\", APR_MODEL_DIR,\n",
    "    \"--batch_size\", \"4\",\n",
    "    \"--exp_metadata_file\", EXP_METADATA_FILE,\n",
    "    \"--results_file\", APR_RESULTS_FILE,\n",
    "    \"--epoch_results_dir\", EPOCH_RESULTS_DIR,\n",
    "    \"--params_dir\", PARAMS_DIR\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/wavlm-large were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of WavLMModel were not initialized from the model checkpoint at microsoft/wavlm-large and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hparams_file, run_opts, overrides = sb.parse_arguments(argv)\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "lexicon_path = \"resources/lexicon\"\n",
    "ckpt_path = \"results/apr/save/best\"\n",
    "label_encoder_path = \"results/apr/save/label_encoder.txt\"\n",
    "\n",
    "hparams[\"ckpt_path\"] = ckpt_path\n",
    "hparams[\"label_encoder_path\"] = label_encoder_path\n",
    "label_encoder_path = hparams[\"label_encoder_path\"]\n",
    "\n",
    "prep_model, hparams = init_model(hparams)\n",
    "label_encoder = sb.dataio.encoder.CTCTextEncoder.from_saved(label_encoder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import apr_dataio_prep\n",
    "\n",
    "train_data, valid_data, test_data, label_encoder = apr_dataio_prep(hparams, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'MBWM0_SI1934.WAV',\n",
       " 'sig': tensor([3.0518e-04, 3.0518e-05, 9.1553e-05,  ..., 3.0518e-05, 3.9673e-04,\n",
       "         1.8311e-04]),\n",
       " 'phn_encoded': tensor([43,  8, 10, 16, 17, 23, 42, 16, 23,  8, 21, 23, 43]),\n",
       " 'phn_encoded_eos': tensor([43,  8, 10, 16, 17, 23, 42, 16, 23,  8, 21, 23, 43,  1]),\n",
       " 'phn_encoded_bos': tensor([ 0, 43,  8, 10, 16, 17, 23, 42, 16, 23,  8, 21, 23, 43])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = valid_data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil', 'w', 'ey', 't', 'ah', 'l', 'ih', 't', 'l', 'w', 'ay', 'l', 'sil']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phns = label_encoder.decode_ndim(sample[\"phn_encoded\"])\n",
    "phns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = sample[\"sig\"].unsqueeze(0).cuda()\n",
    "wav_lens = torch.tensor([wavs.shape[1]]).cuda()\n",
    "phn_encoded = sample[\"phn_encoded\"].unsqueeze(0).cuda()\n",
    "phns_eos = sample[\"phn_encoded_eos\"].unsqueeze(0).cuda()\n",
    "phns_bos = sample[\"phn_encoded_bos\"].unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctc, p_seq, wav_lens = prep_model.infer(wavs, wav_lens, phns_bos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 46])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 54, 46])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ctc.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2er",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
