{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/codes/sb-apa/\n",
    "\n",
    "from src.brain import get_brain_class\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import speechbrain as sb\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from utils.arpa import arpa_to_ipa\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(hparams):\n",
    "    wav2vec2_ckpt_path = f'{ckpt_path}/wav2vec2.ckpt'\n",
    "    model_ckpt_path = f'{ckpt_path}/model.ckpt'\n",
    "\n",
    "    wav2vec2_state_dict = torch.load(wav2vec2_ckpt_path)\n",
    "    model_state_dict = torch.load(model_ckpt_path)\n",
    "\n",
    "    hparams[\"wav2vec2\"].load_state_dict(wav2vec2_state_dict)\n",
    "    hparams[\"model\"].load_state_dict(model_state_dict)\n",
    "\n",
    "    return hparams\n",
    "\n",
    "def init_model(hparams):\n",
    "    brain_class = get_brain_class(hparams)\n",
    "\n",
    "    model = brain_class(\n",
    "            modules=hparams[\"modules\"],\n",
    "            hparams=hparams,\n",
    "            run_opts=run_opts,\n",
    "            checkpointer=hparams[\"checkpointer\"],\n",
    "        )\n",
    "\n",
    "    hparams = load_state_dict(hparams)\n",
    "    \n",
    "    for key, value in hparams[\"modules\"].items():\n",
    "        value.eval()\n",
    "    \n",
    "    return model, hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "APR_DATA_FOLDER = f'{DATA_DIR}/apr/'\n",
    "\n",
    "RESULTS_FOLDER = f'{DATA_DIR}/results/'\n",
    "EXP_METADATA_FILE = f'{RESULTS_FOLDER}/exp_metadata.csv'\n",
    "APR_RESULTS_FILE = f'{RESULTS_FOLDER}/results_scoring.csv'\n",
    "EPOCH_RESULTS_DIR = f'{RESULTS_FOLDER}/epoch_results'\n",
    "PARAMS_DIR= f'{RESULTS_FOLDER}/params'\n",
    "\n",
    "\n",
    "MODEL_TYPE = \"w2v2\"\n",
    "SCORING_TYPE=\"\"\n",
    "\n",
    "APR_MODEL_DIR = f\"pretrained/apr\"\n",
    "PRETRAINED_MODEL_DIR = f\"pretrained/apr\"\n",
    "SCORING_HPARAM_FILE = f\"hparams/apr.yml\"\n",
    "\n",
    "argv = [\n",
    "    SCORING_HPARAM_FILE,\n",
    "    \"--data_folder\", APR_DATA_FOLDER,\n",
    "    \"--exp_folder\", APR_MODEL_DIR,\n",
    "    \"--batch_size\", \"4\",\n",
    "    \"--exp_metadata_file\", EXP_METADATA_FILE,\n",
    "    \"--results_file\", APR_RESULTS_FILE,\n",
    "    \"--epoch_results_dir\", EPOCH_RESULTS_DIR,\n",
    "    \"--params_dir\", PARAMS_DIR\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_file, run_opts, overrides = sb.parse_arguments(argv)\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "lexicon_path = \"resources/lexicon\"\n",
    "ckpt_path = \"results/apr/save/best\"\n",
    "label_encoder_path = \"results/apr/save/label_encoder.txt\"\n",
    "\n",
    "hparams[\"ckpt_path\"] = ckpt_path\n",
    "hparams[\"label_encoder_path\"] = label_encoder_path\n",
    "label_encoder_path = hparams[\"label_encoder_path\"]\n",
    "\n",
    "prep_model, hparams = init_model(hparams)\n",
    "label_encoder = sb.dataio.encoder.CTCTextEncoder.from_saved(label_encoder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import apr_dataio_prep\n",
    "\n",
    "train_data, valid_data, test_data, label_encoder = apr_dataio_prep(hparams, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = valid_data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phns = label_encoder.decode_ndim(sample[\"phn_encoded\"])\n",
    "phns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = sample[\"sig\"].unsqueeze(0).cuda()\n",
    "wav_lens = torch.tensor([wavs.shape[1]]).cuda()\n",
    "phn_encoded = sample[\"phn_encoded\"].unsqueeze(0).cuda()\n",
    "phns_eos = sample[\"phn_encoded_eos\"].unsqueeze(0).cuda()\n",
    "phns_bos = sample[\"phn_encoded_bos\"].unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctc, p_seq, wav_lens = prep_model.infer(wavs, wav_lens, phns_bos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctc.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2er",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
