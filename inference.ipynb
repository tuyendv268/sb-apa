{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechbrain as sb\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "PREP_DATA_FOLDER = f'{DATA_DIR}/prep_data/'\n",
    "\n",
    "RESULTS_FOLDER = f'{DATA_DIR}/results/'\n",
    "EXP_METADATA_FILE = f'{RESULTS_FOLDER}/exp_metadata.csv'\n",
    "PREP_SCORING_RESULTS_FILE = f'{RESULTS_FOLDER}/results_scoring_prep.csv'\n",
    "EPOCH_RESULTS_DIR = f'{RESULTS_FOLDER}/epoch_results'\n",
    "PARAMS_DIR= f'{RESULTS_FOLDER}/params'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"w2v2\"\n",
    "SCORING_TYPE=\"\"\n",
    "\n",
    "SCORING_HPARAM_FILE = f'hparams/scoring/{MODEL_TYPE}/train_{MODEL_TYPE}_so762{SCORING_TYPE}_scoring.yaml'\n",
    "SCORING_MODEL_DIR = f\"results/scoring/{MODEL_TYPE}/crdnn_{MODEL_TYPE}_so762{SCORING_TYPE}_scoring_aug_no_round_no_pre_train\"\n",
    "PRETRAINED_MODEL_DIR = f\"results/apr/{MODEL_TYPE}/crdnn_{MODEL_TYPE}_timit_apr/1234\"\n",
    "SCORING_HPARAM_FILE = f\"hparams/scoring/{MODEL_TYPE}/train_{MODEL_TYPE}_so762{SCORING_TYPE}_scoring.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = [\n",
    "    SCORING_HPARAM_FILE,\n",
    "    \"--data_folder\", PREP_DATA_FOLDER,\n",
    "    \"--batch_size\", \"4\",\n",
    "    \"--pretrained_model_folder\", PRETRAINED_MODEL_DIR,\n",
    "    \"--use_augmentation\", \"True\",\n",
    "    \"--exp_folder\", SCORING_MODEL_DIR,\n",
    "    \"--exp_metadata_file\", EXP_METADATA_FILE,\n",
    "    \"--results_file\", PREP_SCORING_RESULTS_FILE,\n",
    "    \"--epoch_results_dir\", EPOCH_RESULTS_DIR,\n",
    "    \"--params_dir\", PARAMS_DIR\n",
    "    ]\n",
    "\n",
    "hparams_file, run_opts, overrides = sb.parse_arguments(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.brain import get_brain_class\n",
    "\n",
    "brain_class = get_brain_class(hparams)\n",
    "brain = brain_class(\n",
    "        modules=hparams[\"modules\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"results/scoring/w2v2/crdnn_w2v2_so762_scoring_aug_no_round_no_pre_train/1234/save-1/CKPT+2024-01-30+08-10-42+00\"\n",
    "\n",
    "wav2vec2_ckpt_path = f'{ckpt_path}/wav2vec2.ckpt'\n",
    "model_ckpt_path = f'{ckpt_path}/model.ckpt'\n",
    "model_scorer_ckpt_path = f'{ckpt_path}/model_scorer.ckpt'\n",
    "\n",
    "wav2vec2_state_dict = torch.load(wav2vec2_ckpt_path)\n",
    "model_state_dict = torch.load(model_ckpt_path)\n",
    "model_scorer_state_dict = torch.load(model_scorer_ckpt_path)\n",
    "\n",
    "hparams[\"wav2vec2\"].load_state_dict(wav2vec2_state_dict)\n",
    "hparams[\"model\"].load_state_dict(model_state_dict)\n",
    "hparams[\"model_scorer\"].load_state_dict(model_scorer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams[\"label_encoder_path\"] = \"results/scoring/w2v2/crdnn_w2v2_so762_scoring_aug_no_round_no_pre_train/1234/save/label_encoder.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_path = hparams[\"label_encoder_path\"]\n",
    "label_encoder = sb.dataio.encoder.CTCTextEncoder.from_saved(label_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep_utils.dataset_preparation.dataio_prep import dataio_prep\n",
    "\n",
    "train_data, valid_data, test_data, label_encoder = dataio_prep(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = re.sub(\n",
    "        r'[\\!@#$%^&*\\(\\)\\\\\\.\\\"\\,\\?\\;\\:\\+\\-\\_\\/\\|~`]', ' ', text)\n",
    "    \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tuyendv/E2E-R/resources/lexicon\"\n",
    "lexicon = pd.read_csv(path, names=[\"word\", \"arpa\"], sep=\"\\t\")\n",
    "\n",
    "lexicon.dropna(inplace=True)\n",
    "lexicon[\"word\"] = lexicon.word.apply(lambda x: x.lower())\n",
    "lexicon[\"arpa\"] = lexicon.arpa.apply(lambda x: re.sub(\"\\d\", \"\", x).lower())\n",
    "\n",
    "lexicon.word.drop_duplicates(inplace=True)\n",
    "lexicon.set_index(\"word\", inplace=True)\n",
    "lexicon = lexicon.to_dict()[\"arpa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/home/tuyendv/E2E-R/wav/I assured that the sessions all my team worth it. Two weeks to start right as a language..wav\"\n",
    "transcript = \"i assured that the sessions all my team worth it two weeks to start right as a language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = normalize(transcript)\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_arpa(word):\n",
    "    word = lexicon[word].lower()\n",
    "    word = word.replace(\"ax\", \"ah\")\n",
    "    word = word.split()\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = transcript.split()\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"word\": words,\n",
    "        \"word-id\": range(len(words))\n",
    "    }\n",
    ")\n",
    "df[\"phone\"] = df[\"word\"].apply(convert_word_to_arpa)\n",
    "df = df.explode(column=\"phone\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phn_canonical_list = df[\"phone\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phn_encoded_list = label_encoder.encode_sequence(phn_canonical_list)\n",
    "phn_canonical_encoded = torch.LongTensor(phn_encoded_list)\n",
    "phn_canonical_encoded_eos = torch.LongTensor(label_encoder.append_eos_index(phn_encoded_list))\n",
    "phn_canonical_encoded_bos = torch.LongTensor(label_encoder.prepend_bos_index(phn_encoded_list))\n",
    "\n",
    "wavs = sb.dataio.dataio.read_audio(audio_path)\n",
    "wavs = wavs.unsqueeze(0).cuda()\n",
    "wav_lens = torch.tensor([wavs.shape[1]]).cuda()\n",
    "phns_canonical_bos = phn_canonical_encoded_bos.unsqueeze(0).cuda()\n",
    "phns_canonical_eos = phn_canonical_encoded_eos.unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pred, wav_lens = brain.infer(wavs, wav_lens, phns_canonical_bos, phns_canonical_eos)\n",
    "scores_pred = (scores_pred * 100).cpu().round()\n",
    "print(scores_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"phone-score\"] = scores_pred[0].tolist()[:-1]\n",
    "df[\"start-time\"] = 0\n",
    "df[\"end-time\"] = 0\n",
    "df[\"start-index\"] = 0\n",
    "df[\"end-index\"] = 0\n",
    "df[\"ipa\"] = \"\"\n",
    "df[\"sound_most_like\"] = df[\"phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = {\n",
    "    \"utterance\": transcript, \n",
    "    \"duration\": 0,\n",
    "    \"text\": transcript,\n",
    "    \"score\": 0,\n",
    "    \"ipa\": \"\",\n",
    "    \"version\": \"v1.0\"\n",
    "    \"words\": [],\n",
    "}\n",
    "\n",
    "sentence[\"words\"] = [None] * (df[\"word-id\"].max() + 1)\n",
    "for (word, word_id), group in df.groupby([\"word\", \"word-id\"]):\n",
    "    group = group.reset_index()\n",
    "\n",
    "    word = {\n",
    "        \"start_time\": 0,\n",
    "        \"end_time\": 0,\n",
    "        \"start_index\": 0,\n",
    "        \"end_index\": 0,\n",
    "        \"text\": word,\n",
    "        \"arpabet\": \"\",\n",
    "        \"ipa\": \"\",\n",
    "        \"score\": 0,\n",
    "        \"phonemes\": []\n",
    "    }\n",
    "    for phone_index in group.index:\n",
    "        phone = {\n",
    "            \"start_time\": group[\"start-time\"][phone_index],\n",
    "            \"end_time\": group[\"end-time\"][phone_index],\n",
    "            \"start_index\": group[\"start-index\"][phone_index],\n",
    "            \"end_index\": group[\"end-index\"][phone_index],\n",
    "            \"arpabet\": group[\"phone\"][phone_index],\n",
    "            \"ipa\": group[\"ipa\"][phone_index],\n",
    "            \"sound_most_like\": group[\"sound_most_like\"][phone_index],\n",
    "            \"score\": group[\"phone-score\"][phone_index]\n",
    "        }\n",
    "\n",
    "        word[\"phonemes\"].append(phone)\n",
    "\n",
    "    sentence[\"words\"][word_id] = word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
